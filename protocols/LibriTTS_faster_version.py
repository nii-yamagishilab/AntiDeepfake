#!/usr/bin/env python
"""Faster script to create protocol for LibriTTS database
This script needs a file list generated by running:

find /path/to/your/LibriTTS -name *.wav > LibriTTS.txt

(inspired by https://github.com/gemelo-ai/vocos/tree/main)

Generating this LibriTTS.txt filelist took ~1min in our server head node, should be faster
in most machines. It looks like this:                    
/my/base_path/Data/LibriTTS/dev-clean/84/121123/84_121123_000020_000004.wav
/my/base_path/Data/LibriTTS/dev-clean/84/121123/84_121123_000036_000000.wav
/my/base_path/Data/LibriTTS/dev-clean/84/121123/84_121123_000069_000000.wav

Now, we can skip scanning the whole LibriTTS folder with python os.walk(),
and use parallel_apply() to speed up.
You are encouraged to apply similar modifications for generating protocols for 
other large datasets, such as VoxCeleb or your own vocoded datasets.

no fake audios in this database

/path/to/your/LibriTTS/
├── dev-clean/
│   ├── ../../xx.flac
├── dev-other/
│   ├── . . .
├── . . .

LibriSpeech.csv:
"""
import os
import csv

try:
    import pandas as pd
    from pandarallel import pandarallel
    import torchaudio
except ImportError:
    print("Please install pandas, pandarallel and torchaudio")
    sys.exit(1)


__author__ = "Wanying Ge, Xin Wang"
__email__ = "gewanying@nii.ac.jp, wangxin@nii.ac.jp"
__copyright__ = "Copyright 2025, National Institute of Informatics"

# used for pandas pd.parallel_apply() to speed up
pandarallel.initialize()

# Define paths
root_folder = '/gs/bs/tgh-25IAB/gewanying/Data/'
dataset_name = 'LibriTTS'
data_folder = root_folder + dataset_name
protocol_file = dataset_name + '.txt'
ID_PREFIX = 'Libri-'
output_csv = dataset_name + '.csv'

# Function to read the protocol file
def read_protocol(protocol_file):
    # define converter
    metadata = pd.read_csv(
        protocol_file,
        sep=' ',
        header=None,
        names=['ID'],
    )
    print(metadata.head())
    return metadata

# Function to collect additional metadata (duration and sample rate)
def collect_audio_metadata(metadata, root_folder):
    def __get_audio_meta(row):
        file_path = row['ID']
        if os.path.exists(file_path):
            metainfo = torchaudio.info(file_path)
            sample_rate = metainfo.sample_rate
            num_channels = metainfo.num_channels
            duration = round(metainfo.num_frames / sample_rate, 2)
            filepath = file_path.replace(root_folder, "$ROOT/")
            parts = os.path.normpath(filepath).split(os.sep)
# ['$ROOT', 'LibriTTS', 'train-clean-360', '166', '122789', '166_122789_000035_000001.wav']
            subset = parts[2]
            if 'train' in subset:
                proportion = 'train'
            elif 'dev' in subset:
                proportion = 'valid'
            elif 'test' in subset:
                proportion = 'test'
            speaker = parts[3]
            label = 'real'
            attack = '-'
            language = 'EN'
            encoding = metainfo.encoding
            bitpersample = metainfo.bits_per_sample
            file_id = os.path.basename(file_path)
        else:
            print(f"Warning: File {file_path} does not exist, skipping entry.")
            duration = -1
            sample_rate = -1
            filepath = ""
            encoding = ""
            bitpersample = -1
            num_channels = -1
            speaker = ""
            language = ""
            proportion = ""
            attack = ""
            label = ""
            file_id = ""
        row["ID"] = ID_PREFIX + file_id
        row["Attack"] = attack
        row["Speaker"] = speaker
        row['Label'] = label
        row["Duration"] = duration
        row["SampleRate"] = sample_rate
        row["Path"] = filepath
        row["Proportion"] = proportion
        row["AudioChannel"] = num_channels
        row["AudioEncoding"] = encoding
        row["AudioBitSample"] = bitpersample
        row["Language"] = language
        return row

    metadata = metadata.parallel_apply(lambda x: __get_audio_meta(x), axis=1)
    return metadata

# Write to CSV
def write_csv(metadata):
    header = ["ID", "Label", "Duration", "SampleRate", "Path", "Attack", "Speaker",\
              "Proportion", "AudioChannel", "AudioEncoding", "AudioBitSample",\
              "Language"]
    metadata = pd.DataFrame(metadata)
    metadata = metadata[header]
    metadata.to_csv(output_csv, index=False)

# Main script
if __name__ == "__main__":
    # Step 1: Read protocol and collect initial metadata
    metadata = read_protocol(protocol_file)
    # Step 2: Collect audio metadata (duration, sample rate, etc.)
    metadata = collect_audio_metadata(metadata, root_folder)
    metadata = metadata.to_dict(orient='records')
    # Step 3: Write metadata to CSV
    write_csv(metadata)
    print(f"Metadata CSV written to {output_csv}")
